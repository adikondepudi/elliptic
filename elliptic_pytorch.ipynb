{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adikondepudi/miniforge3/lib/python3.10/site-packages/torch/_tensor_str.py:115: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/miniforge3/conda-bld/pytorch-recipe_1670076285409/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "df_features = pd.read_csv(\"./elliptic/elliptic_txs_features.csv\", header=None)\n",
    "df_classes= pd.read_csv(\"./elliptic/elliptic_txs_classes.csv\")\n",
    "df_edgelist = pd.read_csv(\"./elliptic/elliptic_txs_edgelist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes.loc[df_classes['class'] == '1', 'class'] = \"illicit\"\n",
    "df_classes.loc[df_classes['class'] == '2', 'class'] = \"licit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230425980</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5530458</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232022460</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232438397</td>\n",
       "      <td>licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230460314</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    class\n",
       "0  230425980  unknown\n",
       "1    5530458  unknown\n",
       "2  232022460  unknown\n",
       "3  232438397    licit\n",
       "4  230460314  unknown"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renaming columns\n",
    "df_features.columns = [\"id\", \"time step\"] + [f\"local_feat_{i}\" for i in range(93)] + [f\"agg_feat_{i}\" for i in range(72)]\n",
    "df_classes.columns = [\"id\", \"class\"]\n",
    "df_features.head()\n",
    "df_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>time step</th>\n",
       "      <th>local_feat_0</th>\n",
       "      <th>local_feat_1</th>\n",
       "      <th>local_feat_2</th>\n",
       "      <th>local_feat_3</th>\n",
       "      <th>local_feat_4</th>\n",
       "      <th>local_feat_5</th>\n",
       "      <th>local_feat_6</th>\n",
       "      <th>...</th>\n",
       "      <th>agg_feat_62</th>\n",
       "      <th>agg_feat_63</th>\n",
       "      <th>agg_feat_64</th>\n",
       "      <th>agg_feat_65</th>\n",
       "      <th>agg_feat_66</th>\n",
       "      <th>agg_feat_67</th>\n",
       "      <th>agg_feat_68</th>\n",
       "      <th>agg_feat_69</th>\n",
       "      <th>agg_feat_70</th>\n",
       "      <th>agg_feat_71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230425980</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171469</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562153</td>\n",
       "      <td>-0.600999</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5530458</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171484</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947382</td>\n",
       "      <td>0.673103</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232022460</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.172107</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670883</td>\n",
       "      <td>0.439728</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232438397</td>\n",
       "      <td>licit</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>1.963790</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>12.409294</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>9.782742</td>\n",
       "      <td>12.414558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230460314</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011523</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.312656</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511871</td>\n",
       "      <td>-0.400422</td>\n",
       "      <td>0.517257</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>1.293750</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.179117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    class  time step  local_feat_0  local_feat_1  local_feat_2  \\\n",
       "0  230425980  unknown          1     -0.171469     -0.184668     -1.201369   \n",
       "1    5530458  unknown          1     -0.171484     -0.184668     -1.201369   \n",
       "2  232022460  unknown          1     -0.172107     -0.184668     -1.201369   \n",
       "3  232438397    licit          1      0.163054      1.963790     -0.646376   \n",
       "4  230460314  unknown          1      1.011523     -0.081127     -1.201369   \n",
       "\n",
       "   local_feat_3  local_feat_4  local_feat_5  local_feat_6  ...  agg_feat_62  \\\n",
       "0     -0.121970     -0.043875     -0.113002     -0.061584  ...    -0.562153   \n",
       "1     -0.121970     -0.043875     -0.113002     -0.061584  ...     0.947382   \n",
       "2     -0.121970     -0.043875     -0.113002     -0.061584  ...     0.670883   \n",
       "3     12.409294     -0.063725      9.782742     12.414558  ...    -0.577099   \n",
       "4      1.153668      0.333276      1.312656     -0.061584  ...    -0.511871   \n",
       "\n",
       "   agg_feat_63  agg_feat_64  agg_feat_65  agg_feat_66  agg_feat_67  \\\n",
       "0    -0.600999     1.461330     1.461369     0.018279    -0.087490   \n",
       "1     0.673103    -0.979074    -0.978556     0.018279    -0.087490   \n",
       "2     0.439728    -0.979074    -0.978556    -0.098889    -0.106715   \n",
       "3    -0.613614     0.241128     0.241406     1.072793     0.085530   \n",
       "4    -0.400422     0.517257     0.579382     0.018279     0.277775   \n",
       "\n",
       "   agg_feat_68  agg_feat_69  agg_feat_70  agg_feat_71  \n",
       "0    -0.131155    -0.097524    -0.120613    -0.119792  \n",
       "1    -0.131155    -0.097524    -0.120613    -0.119792  \n",
       "2    -0.131155    -0.183671    -0.120613    -0.119792  \n",
       "3    -0.131155     0.677799    -0.120613    -0.119792  \n",
       "4     0.326394     1.293750     0.178136     0.179117  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding class data\n",
    "df = pd.merge(df_features, df_classes, how=\"inner\", on=\"id\")\n",
    "second_column = df.pop('class')\n",
    "df.insert(1, 'class', second_column)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>time step</th>\n",
       "      <th>local_feat_0</th>\n",
       "      <th>local_feat_1</th>\n",
       "      <th>local_feat_2</th>\n",
       "      <th>local_feat_3</th>\n",
       "      <th>local_feat_4</th>\n",
       "      <th>local_feat_5</th>\n",
       "      <th>local_feat_6</th>\n",
       "      <th>...</th>\n",
       "      <th>agg_feat_62</th>\n",
       "      <th>agg_feat_63</th>\n",
       "      <th>agg_feat_64</th>\n",
       "      <th>agg_feat_65</th>\n",
       "      <th>agg_feat_66</th>\n",
       "      <th>agg_feat_67</th>\n",
       "      <th>agg_feat_68</th>\n",
       "      <th>agg_feat_69</th>\n",
       "      <th>agg_feat_70</th>\n",
       "      <th>agg_feat_71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232438397</td>\n",
       "      <td>licit</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>1.963790</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>12.409294</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>9.782742</td>\n",
       "      <td>12.414558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>232029206</td>\n",
       "      <td>licit</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.005027</td>\n",
       "      <td>0.578941</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>4.380281</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>4.667146</td>\n",
       "      <td>0.851305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.604120</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.333211</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>232344069</td>\n",
       "      <td>licit</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.147852</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27553029</td>\n",
       "      <td>licit</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.151357</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.539735</td>\n",
       "      <td>-0.582077</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3881097</td>\n",
       "      <td>licit</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.172306</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.029140</td>\n",
       "      <td>0.242712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.600999</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>-0.084674</td>\n",
       "      <td>-0.054450</td>\n",
       "      <td>-1.760926</td>\n",
       "      <td>-1.760984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  class  time step  local_feat_0  local_feat_1  local_feat_2  \\\n",
       "3   232438397  licit          1      0.163054      1.963790     -0.646376   \n",
       "9   232029206  licit          1     -0.005027      0.578941     -0.091383   \n",
       "10  232344069  licit          1     -0.147852     -0.184668     -1.201369   \n",
       "11   27553029  licit          1     -0.151357     -0.184668     -1.201369   \n",
       "16    3881097  licit          1     -0.172306     -0.184668     -1.201369   \n",
       "\n",
       "    local_feat_3  local_feat_4  local_feat_5  local_feat_6  ...  agg_feat_62  \\\n",
       "3      12.409294     -0.063725      9.782742     12.414558  ...    -0.577099   \n",
       "9       4.380281     -0.063725      4.667146      0.851305  ...    -0.577099   \n",
       "10     -0.121970     -0.043875     -0.113002     -0.061584  ...    -0.577099   \n",
       "11     -0.121970     -0.043875     -0.113002     -0.061584  ...    -0.539735   \n",
       "16      0.028105     -0.043875     -0.029140      0.242712  ...    -0.577099   \n",
       "\n",
       "    agg_feat_63  agg_feat_64  agg_feat_65  agg_feat_66  agg_feat_67  \\\n",
       "3     -0.613614     0.241128     0.241406     1.072793     0.085530   \n",
       "9     -0.613614     0.241128     0.241406     0.604120     0.008632   \n",
       "10    -0.613614     0.241128     0.241406     0.018279    -0.087490   \n",
       "11    -0.582077    -0.979074    -0.978556     0.018279    -0.087490   \n",
       "16    -0.600999     0.241128     0.241406     0.018279    -0.068266   \n",
       "\n",
       "    agg_feat_68  agg_feat_69  agg_feat_70  agg_feat_71  \n",
       "3     -0.131155     0.677799    -0.120613    -0.119792  \n",
       "9     -0.131155     0.333211    -0.120613    -0.119792  \n",
       "10    -0.131155    -0.097524    -0.120613    -0.119792  \n",
       "11    -0.131155    -0.097524    -0.120613    -0.119792  \n",
       "16    -0.084674    -0.054450    -1.760926    -1.760984  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_licit_illicit = df[df[\"class\"] != \"unknown\"]\n",
    "df_licit_illicit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_licit_illicit.iloc[:, 0:2]\n",
    "y = y.drop([\"id\"], axis=1).values\n",
    "X = df_licit_illicit.drop([\"class\", \"id\", \"time step\"], axis=1).values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = y.ravel()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.from_numpy(X).float()\n",
    "y_tensor = torch.from_numpy(y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset to hold the data\n",
    "data = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = torch.utils.data.random_split(data, [int(0.8 * len(data)), len(data) - int(0.8 * len(data))])\n",
    "\n",
    "# Create data loaders for the training and test sets\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(in_features=X.shape[1], out_features=64)\n",
    "        self.fc2 = torch.nn.Linear(in_features=64, out_features=64)\n",
    "        self.fc3 = torch.nn.Linear(in_features=64, out_features=len(set(y)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu 1.3819190000067465\n",
      "gpu 17.970439917000476\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "a_cpu = torch.rand(250, device='cpu')\n",
    "b_cpu = torch.rand((250, 250), device='cpu')\n",
    "a_mps = torch.rand(250, device='mps')\n",
    "b_mps = torch.rand((250, 250), device='mps')\n",
    "\n",
    "print('cpu', timeit.timeit(lambda: a_cpu @ b_cpu, number=100_000))\n",
    "print('gpu', timeit.timeit(lambda: a_mps @ b_mps, number=100_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the network\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "for epoch in range(10):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the network\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy: {correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unknown = df[df[\"class\"] == \"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_feat_0</th>\n",
       "      <th>local_feat_1</th>\n",
       "      <th>local_feat_2</th>\n",
       "      <th>local_feat_3</th>\n",
       "      <th>local_feat_4</th>\n",
       "      <th>local_feat_5</th>\n",
       "      <th>local_feat_6</th>\n",
       "      <th>local_feat_7</th>\n",
       "      <th>local_feat_8</th>\n",
       "      <th>local_feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>agg_feat_62</th>\n",
       "      <th>agg_feat_63</th>\n",
       "      <th>agg_feat_64</th>\n",
       "      <th>agg_feat_65</th>\n",
       "      <th>agg_feat_66</th>\n",
       "      <th>agg_feat_67</th>\n",
       "      <th>agg_feat_68</th>\n",
       "      <th>agg_feat_69</th>\n",
       "      <th>agg_feat_70</th>\n",
       "      <th>agg_feat_71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.171469</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162097</td>\n",
       "      <td>-0.167933</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562153</td>\n",
       "      <td>-0.600999</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.171484</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162112</td>\n",
       "      <td>-0.167948</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947382</td>\n",
       "      <td>0.673103</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.172107</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162749</td>\n",
       "      <td>-0.168576</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670883</td>\n",
       "      <td>0.439728</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.011523</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.312656</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163523</td>\n",
       "      <td>0.041399</td>\n",
       "      <td>0.935886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511871</td>\n",
       "      <td>-0.400422</td>\n",
       "      <td>0.517257</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>1.293750</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.179117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.961040</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.303743</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.480381</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163577</td>\n",
       "      <td>0.038305</td>\n",
       "      <td>0.816377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504702</td>\n",
       "      <td>-0.422589</td>\n",
       "      <td>-0.226790</td>\n",
       "      <td>-0.117629</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.413931</td>\n",
       "      <td>1.149556</td>\n",
       "      <td>-0.696053</td>\n",
       "      <td>-0.695540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   local_feat_0  local_feat_1  local_feat_2  local_feat_3  local_feat_4  \\\n",
       "0     -0.171469     -0.184668     -1.201369     -0.121970     -0.043875   \n",
       "1     -0.171484     -0.184668     -1.201369     -0.121970     -0.043875   \n",
       "2     -0.172107     -0.184668     -1.201369     -0.121970     -0.043875   \n",
       "4      1.011523     -0.081127     -1.201369      1.153668      0.333276   \n",
       "5      0.961040     -0.081127     -1.201369      1.303743      0.333276   \n",
       "\n",
       "   local_feat_5  local_feat_6  local_feat_7  local_feat_8  local_feat_9  ...  \\\n",
       "0     -0.113002     -0.061584     -0.162097     -0.167933     -0.049707  ...   \n",
       "1     -0.113002     -0.061584     -0.162112     -0.167948     -0.049707  ...   \n",
       "2     -0.113002     -0.061584     -0.162749     -0.168576     -0.049707  ...   \n",
       "4      1.312656     -0.061584     -0.163523      0.041399      0.935886  ...   \n",
       "5      1.480381     -0.061584     -0.163577      0.038305      0.816377  ...   \n",
       "\n",
       "   agg_feat_62  agg_feat_63  agg_feat_64  agg_feat_65  agg_feat_66  \\\n",
       "0    -0.562153    -0.600999     1.461330     1.461369     0.018279   \n",
       "1     0.947382     0.673103    -0.979074    -0.978556     0.018279   \n",
       "2     0.670883     0.439728    -0.979074    -0.978556    -0.098889   \n",
       "4    -0.511871    -0.400422     0.517257     0.579382     0.018279   \n",
       "5    -0.504702    -0.422589    -0.226790    -0.117629     0.018279   \n",
       "\n",
       "   agg_feat_67  agg_feat_68  agg_feat_69  agg_feat_70  agg_feat_71  \n",
       "0    -0.087490    -0.131155    -0.097524    -0.120613    -0.119792  \n",
       "1    -0.087490    -0.131155    -0.097524    -0.120613    -0.119792  \n",
       "2    -0.106715    -0.131155    -0.183671    -0.120613    -0.119792  \n",
       "4     0.277775     0.326394     1.293750     0.178136     0.179117  \n",
       "5     0.277775     0.413931     1.149556    -0.696053    -0.695540  \n",
       "\n",
       "[5 rows x 165 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unknown = df_unknown.drop(['class', 'time step', \"id\"], axis=1)\n",
    "df_unknown.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unknown = df_unknown.values\n",
    "df_unknown_tensor = torch.from_numpy(df_unknown).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the neural network to classify the new data\n",
    "with torch.no_grad():\n",
    "    # Run the new data through the network\n",
    "    df_unknown_tensor = df_unknown_tensor.to(device)\n",
    "    output = net(df_unknown_tensor)\n",
    "    # Get the predicted class for each sample\n",
    "    _, predicted = torch.max(output.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predicted.cpu()\n",
    "predicted = le.inverse_transform(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df_unknown = df[df[\"class\"] == \"unknown\"]\n",
    "df_df_unknown = df_df_unknown.drop(['class', 'time step', \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df_unknown['classes'] = predicted.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_feat_0</th>\n",
       "      <th>local_feat_1</th>\n",
       "      <th>local_feat_2</th>\n",
       "      <th>local_feat_3</th>\n",
       "      <th>local_feat_4</th>\n",
       "      <th>local_feat_5</th>\n",
       "      <th>local_feat_6</th>\n",
       "      <th>local_feat_7</th>\n",
       "      <th>local_feat_8</th>\n",
       "      <th>local_feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>agg_feat_63</th>\n",
       "      <th>agg_feat_64</th>\n",
       "      <th>agg_feat_65</th>\n",
       "      <th>agg_feat_66</th>\n",
       "      <th>agg_feat_67</th>\n",
       "      <th>agg_feat_68</th>\n",
       "      <th>agg_feat_69</th>\n",
       "      <th>agg_feat_70</th>\n",
       "      <th>agg_feat_71</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.171469</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162097</td>\n",
       "      <td>-0.167933</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.600999</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.171484</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162112</td>\n",
       "      <td>-0.167948</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673103</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.172107</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162749</td>\n",
       "      <td>-0.168576</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439728</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.011523</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.312656</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163523</td>\n",
       "      <td>0.041399</td>\n",
       "      <td>0.935886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400422</td>\n",
       "      <td>0.517257</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>1.293750</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.179117</td>\n",
       "      <td>licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.961040</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.303743</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.480381</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163577</td>\n",
       "      <td>0.038305</td>\n",
       "      <td>0.816377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422589</td>\n",
       "      <td>-0.226790</td>\n",
       "      <td>-0.117629</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.413931</td>\n",
       "      <td>1.149556</td>\n",
       "      <td>-0.696053</td>\n",
       "      <td>-0.695540</td>\n",
       "      <td>licit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   local_feat_0  local_feat_1  local_feat_2  local_feat_3  local_feat_4  \\\n",
       "0     -0.171469     -0.184668     -1.201369     -0.121970     -0.043875   \n",
       "1     -0.171484     -0.184668     -1.201369     -0.121970     -0.043875   \n",
       "2     -0.172107     -0.184668     -1.201369     -0.121970     -0.043875   \n",
       "4      1.011523     -0.081127     -1.201369      1.153668      0.333276   \n",
       "5      0.961040     -0.081127     -1.201369      1.303743      0.333276   \n",
       "\n",
       "   local_feat_5  local_feat_6  local_feat_7  local_feat_8  local_feat_9  ...  \\\n",
       "0     -0.113002     -0.061584     -0.162097     -0.167933     -0.049707  ...   \n",
       "1     -0.113002     -0.061584     -0.162112     -0.167948     -0.049707  ...   \n",
       "2     -0.113002     -0.061584     -0.162749     -0.168576     -0.049707  ...   \n",
       "4      1.312656     -0.061584     -0.163523      0.041399      0.935886  ...   \n",
       "5      1.480381     -0.061584     -0.163577      0.038305      0.816377  ...   \n",
       "\n",
       "   agg_feat_63  agg_feat_64  agg_feat_65  agg_feat_66  agg_feat_67  \\\n",
       "0    -0.600999     1.461330     1.461369     0.018279    -0.087490   \n",
       "1     0.673103    -0.979074    -0.978556     0.018279    -0.087490   \n",
       "2     0.439728    -0.979074    -0.978556    -0.098889    -0.106715   \n",
       "4    -0.400422     0.517257     0.579382     0.018279     0.277775   \n",
       "5    -0.422589    -0.226790    -0.117629     0.018279     0.277775   \n",
       "\n",
       "   agg_feat_68  agg_feat_69  agg_feat_70  agg_feat_71  classes  \n",
       "0    -0.131155    -0.097524    -0.120613    -0.119792    licit  \n",
       "1    -0.131155    -0.097524    -0.120613    -0.119792    licit  \n",
       "2    -0.131155    -0.183671    -0.120613    -0.119792    licit  \n",
       "4     0.326394     1.293750     0.178136     0.179117    licit  \n",
       "5     0.413931     1.149556    -0.696053    -0.695540    licit  \n",
       "\n",
       "[5 rows x 166 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_df_unknown.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='classes', ylabel='Count'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "data = df_df_unknown[\"classes\"]\n",
    "sns.histplot(data, bins=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:13) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a5edab282632443219e051e4ade2d1d5bbc671c781051bf1437897cbdfea0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
